{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46a02b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pytesseract #detection of characters\n",
    "from ultralytics import YOLO   \n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "#import openpyxl\n",
    "import os\n",
    "import sqlite3   \n",
    "from ultralytics.utils.plotting import Annotator\n",
    "import easyocr\n",
    "reader=easyocr.Reader(['en'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7123c021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.12.4\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107d0d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create the table if it doesn't exist\n",
    "def create_table():\n",
    "    # Connect to the SQLite database\n",
    "    conn = sqlite3.connect(\"numberplate.db\")\n",
    "    # Create a cursor object to execute SQL statements\n",
    "    c = conn.cursor()\n",
    "    # Create the \"vehicles\" table with two columns: \"vehicle_number\" and \"bike_image_path\"\n",
    "    # The \"IF NOT EXISTS\" clause ensures that the table is only created if it doesn't already exist\n",
    "    c.execute(\"CREATE TABLE IF NOT EXISTS vehicles (vehicle_number TEXT, bike_image_path TEXT)\")\n",
    "    # Commit the changes to the database\n",
    "    conn.commit()\n",
    "    # Close the database connection\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7036e568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to insert a record into the \"vehicles\" table\n",
    "def insert_record(vehicle_number, bike_image_path):\n",
    "    # Connect to the SQLite database\n",
    "    conn = sqlite3.connect(\"numberplate.db\")\n",
    "    # Create a cursor object to execute SQL statements\n",
    "    c = conn.cursor()\n",
    "    # Insert the record into the \"vehicles\" table using parameterized SQL statement\n",
    "    c.execute(\"INSERT INTO vehicles VALUES (?, ?)\", (vehicle_number, bike_image_path))\n",
    "    # Commit the changes to the database\n",
    "    conn.commit()\n",
    "    # Close the database connection\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3214cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# workbook = openpyxl.Workbook()\n",
    "# worksheet = workbook.active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd26b330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize YOLO models\n",
    "person_bike_model = YOLO(r\"C:\\Users\\User\\OneDrive\\Desktop\\Final project\\person_bike_model.pt\")\n",
    "helmet_model = YOLO(r\"C:\\Users\\User\\OneDrive\\Desktop\\Final project\\helmet_model.pt\")\n",
    "number_plate_model = YOLO(r\"C:\\Users\\User\\OneDrive\\Desktop\\Final project\\number_plate_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b342d675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Tesseract OCR\n",
    "#pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a78cab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: opencv-python==4.8.1.78 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (4.8.1.78)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from opencv-python==4.8.1.78) (1.26.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install opencv-python==4.8.1.78\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ffc8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tesseract ocr alternative\n",
    "# import easyocr\n",
    "\n",
    "# reader = easyocr.Reader(['en'])\n",
    "# extract_info = reader.readtext(image_path)\n",
    "\n",
    "# for el in extract_info:\n",
    "#    print(el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c1f1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = r\"C:\\Users\\User\\OneDrive\\Desktop\\Final project\\Output\"  # Directory to save the output images for image folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674bcc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# img=r\"C:\\Users\\User\\OneDrive\\Desktop\\Final project\\image3.jpg\"\n",
    "# #model test\n",
    "# person_bike_results = person_bike_model.predict(img, show=True, save=True)\n",
    "# h_results = helmet_model.predict(img, show=True, save=True)\n",
    "# n_results = number_plate_model.predict(img, show=True, save=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c651a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 416x416 2 person_bikes, 2754.9ms\n",
      "Speed: 38.7ms preprocess, 2754.9ms inference, 40.6ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Results saved to \u001b[1mruns\\detect\\predict112\u001b[0m\n",
      "person_bike True\n",
      "\n",
      "0: 416x160 1 Without Helmet, 205.2ms\n",
      "Speed: 9.6ms preprocess, 205.2ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Results saved to \u001b[1mruns\\detect\\predict113\u001b[0m\n",
      "\n",
      "0: 416x160 1 License_Plate, 895.0ms\n",
      "Speed: 0.0ms preprocess, 895.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Results saved to \u001b[1mruns\\detect\\predict114\u001b[0m\n",
      "License_Plate\n",
      "Number Plate Text: ....\n",
      "person_bike True\n",
      "\n",
      "0: 416x224 2 Without Helmets, 165.2ms\n",
      "Speed: 8.0ms preprocess, 165.2ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 224)\n",
      "Results saved to \u001b[1mruns\\detect\\predict113\u001b[0m\n",
      "\n",
      "0: 416x224 (no detections), 1085.1ms\n",
      "Speed: 38.8ms preprocess, 1085.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 224)\n",
      "Results saved to \u001b[1mruns\\detect\\predict114\u001b[0m\n",
      "\n",
      "0: 416x224 (no detections), 1176.0ms\n",
      "Speed: 43.6ms preprocess, 1176.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 224)\n",
      "Results saved to \u001b[1mruns\\detect\\predict114\u001b[0m\n",
      "\n",
      "0: 416x416 2 person_bikes, 1979.0ms\n",
      "Speed: 8.0ms preprocess, 1979.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Results saved to \u001b[1mruns\\detect\\predict112\u001b[0m\n",
      "person_bike True\n",
      "\n",
      "0: 416x192 1 Without Helmet, 184.3ms\n",
      "Speed: 0.0ms preprocess, 184.3ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Results saved to \u001b[1mruns\\detect\\predict113\u001b[0m\n",
      "\n",
      "0: 416x192 2 License_Plates, 976.9ms\n",
      "Speed: 0.0ms preprocess, 976.9ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Results saved to \u001b[1mruns\\detect\\predict114\u001b[0m\n",
      "License_Plate\n",
      "Number Plate Text: ERESL7\n",
      "License_Plate\n",
      "Number Plate Text: ....\n",
      "person_bike True\n",
      "\n",
      "0: 416x192 2 Without Helmets, 139.3ms\n",
      "Speed: 12.1ms preprocess, 139.3ms inference, 9.6ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Results saved to \u001b[1mruns\\detect\\predict113\u001b[0m\n",
      "\n",
      "0: 416x192 1 License_Plate, 813.1ms\n",
      "Speed: 0.0ms preprocess, 813.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Results saved to \u001b[1mruns\\detect\\predict114\u001b[0m\n",
      "License_Plate\n",
      "Number Plate Text: ....\n",
      "\n",
      "0: 416x192 1 License_Plate, 859.6ms\n",
      "Speed: 0.0ms preprocess, 859.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Results saved to \u001b[1mruns\\detect\\predict114\u001b[0m\n",
      "License_Plate\n",
      "Number Plate Text: ....\n",
      "\n",
      "0: 288x416 2 person_bikes, 1091.9ms\n",
      "Speed: 8.2ms preprocess, 1091.9ms inference, 0.0ms postprocess per image at shape (1, 3, 288, 416)\n",
      "Results saved to \u001b[1mruns\\detect\\predict112\u001b[0m\n",
      "person_bike True\n",
      "\n",
      "0: 416x224 1 Without Helmet, 174.8ms\n",
      "Speed: 4.9ms preprocess, 174.8ms inference, 2.8ms postprocess per image at shape (1, 3, 416, 224)\n",
      "Results saved to \u001b[1mruns\\detect\\predict113\u001b[0m\n",
      "\n",
      "0: 416x224 (no detections), 883.9ms\n",
      "Speed: 7.8ms preprocess, 883.9ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 224)\n",
      "Results saved to \u001b[1mruns\\detect\\predict114\u001b[0m\n",
      "person_bike True\n",
      "\n",
      "0: 416x192 1 With Helmet, 174.2ms\n",
      "Speed: 0.0ms preprocess, 174.2ms inference, 2.2ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Results saved to \u001b[1mruns\\detect\\predict113\u001b[0m\n",
      "\n",
      "0: 320x416 2 person_bikes, 1213.0ms\n",
      "Speed: 0.0ms preprocess, 1213.0ms inference, 8.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Results saved to \u001b[1mruns\\detect\\predict112\u001b[0m\n",
      "person_bike True\n",
      "\n",
      "0: 416x192 2 Without Helmets, 162.8ms\n",
      "Speed: 8.0ms preprocess, 162.8ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Results saved to \u001b[1mruns\\detect\\predict113\u001b[0m\n",
      "\n",
      "0: 416x192 1 License_Plate, 805.6ms\n",
      "Speed: 6.2ms preprocess, 805.6ms inference, 8.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Results saved to \u001b[1mruns\\detect\\predict114\u001b[0m\n",
      "License_Plate\n",
      "Number Plate Text: BPgg NPC\n",
      "\n",
      "0: 416x192 1 License_Plate, 781.7ms\n",
      "Speed: 8.1ms preprocess, 781.7ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Results saved to \u001b[1mruns\\detect\\predict114\u001b[0m\n",
      "License_Plate\n",
      "Number Plate Text: BPgg NPC\n",
      "person_bike True\n",
      "\n",
      "0: 416x224 1 Without Helmet, 160.2ms\n",
      "Speed: 0.8ms preprocess, 160.2ms inference, 2.0ms postprocess per image at shape (1, 3, 416, 224)\n",
      "Results saved to \u001b[1mruns\\detect\\predict113\u001b[0m\n",
      "\n",
      "0: 416x224 1 License_Plate, 1011.0ms\n",
      "Speed: 21.7ms preprocess, 1011.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 224)\n",
      "Results saved to \u001b[1mruns\\detect\\predict114\u001b[0m\n",
      "License_Plate\n",
      "Number Plate Text: 49P 6327\n",
      "\n",
      "0: 352x416 3 person_bikes, 1342.2ms\n",
      "Speed: 8.0ms preprocess, 1342.2ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 416)\n",
      "Results saved to \u001b[1mruns\\detect\\predict112\u001b[0m\n",
      "person_bike True\n",
      "\n",
      "0: 416x288 1 Without Helmet, 207.0ms\n",
      "Speed: 3.6ms preprocess, 207.0ms inference, 10.7ms postprocess per image at shape (1, 3, 416, 288)\n",
      "Results saved to \u001b[1mruns\\detect\\predict113\u001b[0m\n",
      "\n",
      "0: 416x288 (no detections), 1338.9ms\n",
      "Speed: 0.9ms preprocess, 1338.9ms inference, 2.7ms postprocess per image at shape (1, 3, 416, 288)\n",
      "Results saved to \u001b[1mruns\\detect\\predict114\u001b[0m\n",
      "person_bike True\n",
      "\n",
      "0: 416x128 1 With Helmet, 137.5ms\n",
      "Speed: 8.2ms preprocess, 137.5ms inference, 2.0ms postprocess per image at shape (1, 3, 416, 128)\n",
      "Results saved to \u001b[1mruns\\detect\\predict113\u001b[0m\n",
      "person_bike True\n",
      "\n",
      "0: 416x192 1 With Helmet, 171.7ms\n",
      "Speed: 0.0ms preprocess, 171.7ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Results saved to \u001b[1mruns\\detect\\predict113\u001b[0m\n",
      "\n",
      "0: 416x192 1 person_bike, 821.0ms\n",
      "Speed: 0.0ms preprocess, 821.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Results saved to \u001b[1mruns\\detect\\predict112\u001b[0m\n",
      "person_bike True\n",
      "\n",
      "0: 416x192 1 Without Helmet, 176.5ms\n",
      "Speed: 0.0ms preprocess, 176.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Results saved to \u001b[1mruns\\detect\\predict113\u001b[0m\n",
      "\n",
      "0: 416x192 (no detections), 772.6ms\n",
      "Speed: 0.0ms preprocess, 772.6ms inference, 8.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Results saved to \u001b[1mruns\\detect\\predict114\u001b[0m\n",
      "\n",
      "0: 416x352 1 person_bike, 1476.1ms\n",
      "Speed: 18.6ms preprocess, 1476.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 352)\n",
      "Results saved to \u001b[1mruns\\detect\\predict112\u001b[0m\n",
      "person_bike True\n",
      "\n",
      "0: 416x224 1 Without Helmet, 184.7ms\n",
      "Speed: 0.0ms preprocess, 184.7ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 224)\n",
      "Results saved to \u001b[1mruns\\detect\\predict113\u001b[0m\n",
      "\n",
      "0: 416x224 1 License_Plate, 913.5ms\n",
      "Speed: 8.0ms preprocess, 913.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 224)\n",
      "Results saved to \u001b[1mruns\\detect\\predict114\u001b[0m\n",
      "License_Plate\n",
      "Number Plate Text: KA53E I6574\n",
      "\n",
      "0: 256x416 2 person_bikes, 1003.4ms\n",
      "Speed: 0.0ms preprocess, 1003.4ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "Results saved to \u001b[1mruns\\detect\\predict112\u001b[0m\n",
      "person_bike True\n",
      "\n",
      "0: 416x224 2 Without Helmets, 154.8ms\n",
      "Speed: 10.6ms preprocess, 154.8ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 224)\n",
      "Results saved to \u001b[1mruns\\detect\\predict113\u001b[0m\n",
      "\n",
      "0: 416x224 2 License_Plates, 890.4ms\n",
      "Speed: 7.9ms preprocess, 890.4ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 224)\n",
      "Results saved to \u001b[1mruns\\detect\\predict114\u001b[0m\n",
      "License_Plate\n",
      "Number Plate Text: ....\n",
      "License_Plate\n",
      "Number Plate Text: IeR Z54zk\n",
      "\n",
      "0: 416x224 2 License_Plates, 877.8ms\n",
      "Speed: 8.2ms preprocess, 877.8ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 224)\n",
      "Results saved to \u001b[1mruns\\detect\\predict114\u001b[0m\n",
      "License_Plate\n",
      "Number Plate Text: ....\n",
      "License_Plate\n",
      "Number Plate Text: IeR Z54zk\n",
      "person_bike True\n",
      "\n",
      "0: 416x192 2 Without Helmets, 146.4ms\n",
      "Speed: 0.0ms preprocess, 146.4ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Results saved to \u001b[1mruns\\detect\\predict113\u001b[0m\n",
      "\n",
      "0: 416x192 1 License_Plate, 952.7ms\n",
      "Speed: 0.0ms preprocess, 952.7ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Results saved to \u001b[1mruns\\detect\\predict114\u001b[0m\n",
      "License_Plate\n",
      "Number Plate Text: 855Di\n",
      "\n",
      "0: 416x192 1 License_Plate, 768.6ms\n",
      "Speed: 0.0ms preprocess, 768.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Results saved to \u001b[1mruns\\detect\\predict114\u001b[0m\n",
      "License_Plate\n",
      "Number Plate Text: 855Di\n",
      "\n",
      "0: 416x384 1 person_bike, 1479.7ms\n",
      "Speed: 8.6ms preprocess, 1479.7ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 384)\n",
      "Results saved to \u001b[1mruns\\detect\\predict112\u001b[0m\n",
      "person_bike True\n",
      "\n",
      "0: 416x192 1 Without Helmet, 146.5ms\n",
      "Speed: 8.7ms preprocess, 146.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Results saved to \u001b[1mruns\\detect\\predict113\u001b[0m\n",
      "\n",
      "0: 416x192 (no detections), 798.0ms\n",
      "Speed: 10.2ms preprocess, 798.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Results saved to \u001b[1mruns\\detect\\predict114\u001b[0m\n",
      "\n",
      "0: 416x320 1 person_bike, 1255.7ms\n",
      "Speed: 11.1ms preprocess, 1255.7ms inference, 8.2ms postprocess per image at shape (1, 3, 416, 320)\n",
      "Results saved to \u001b[1mruns\\detect\\predict112\u001b[0m\n",
      "person_bike True\n",
      "\n",
      "0: 416x192 1 Without Helmet, 141.8ms\n",
      "Speed: 8.0ms preprocess, 141.8ms inference, 9.4ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Results saved to \u001b[1mruns\\detect\\predict113\u001b[0m\n",
      "\n",
      "0: 416x192 (no detections), 777.9ms\n",
      "Speed: 5.8ms preprocess, 777.9ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Results saved to \u001b[1mruns\\detect\\predict114\u001b[0m\n",
      "\n",
      "0: 416x384 1 person_bike, 1607.9ms\n",
      "Speed: 0.0ms preprocess, 1607.9ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 384)\n",
      "Results saved to \u001b[1mruns\\detect\\predict112\u001b[0m\n",
      "person_bike True\n",
      "\n",
      "0: 416x192 1 Without Helmet, 141.2ms\n",
      "Speed: 8.5ms preprocess, 141.2ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Results saved to \u001b[1mruns\\detect\\predict113\u001b[0m\n",
      "\n",
      "0: 416x192 2 License_Plates, 775.5ms\n",
      "Speed: 0.0ms preprocess, 775.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Results saved to \u001b[1mruns\\detect\\predict114\u001b[0m\n",
      "License_Plate\n",
      "Number Plate Text: KA 05 INDI 'CP25Lo\n",
      "License_Plate\n",
      "Number Plate Text: 60S8.28 EA,HM\n",
      "\n",
      "0: 416x256 1 person_bike, 1008.7ms\n",
      "Speed: 10.0ms preprocess, 1008.7ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 256)\n",
      "Results saved to \u001b[1mruns\\detect\\predict112\u001b[0m\n",
      "person_bike True\n",
      "\n",
      "0: 416x160 1 With Helmet, 160.8ms\n",
      "Speed: 1.9ms preprocess, 160.8ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Results saved to \u001b[1mruns\\detect\\predict113\u001b[0m\n",
      "\n",
      "0: 416x288 1 person_bike, 1083.1ms\n",
      "Speed: 8.0ms preprocess, 1083.1ms inference, 2.0ms postprocess per image at shape (1, 3, 416, 288)\n",
      "Results saved to \u001b[1mruns\\detect\\predict112\u001b[0m\n",
      "person_bike True\n",
      "\n",
      "0: 416x256 2 With Helmets, 1 Without Helmet, 191.3ms\n",
      "Speed: 8.9ms preprocess, 191.3ms inference, 10.6ms postprocess per image at shape (1, 3, 416, 256)\n",
      "Results saved to \u001b[1mruns\\detect\\predict113\u001b[0m\n",
      "\n",
      "0: 416x256 1 License_Plate, 1008.3ms\n",
      "Speed: 8.0ms preprocess, 1008.3ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 256)\n",
      "Results saved to \u001b[1mruns\\detect\\predict114\u001b[0m\n",
      "License_Plate\n",
      "Number Plate Text: KA 05 CP 2520\n",
      "\n",
      "0: 416x416 1 person_bike, 1523.0ms\n",
      "Speed: 8.0ms preprocess, 1523.0ms inference, 2.7ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Results saved to \u001b[1mruns\\detect\\predict112\u001b[0m\n",
      "person_bike True\n",
      "\n",
      "0: 416x256 (no detections), 176.9ms\n",
      "Speed: 8.0ms preprocess, 176.9ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 256)\n",
      "Results saved to \u001b[1mruns\\detect\\predict113\u001b[0m\n",
      "\n",
      "0: 416x352 1 person_bike, 1323.2ms\n",
      "Speed: 8.0ms preprocess, 1323.2ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 352)\n",
      "Results saved to \u001b[1mruns\\detect\\predict112\u001b[0m\n",
      "person_bike True\n",
      "\n",
      "0: 416x160 1 Without Helmet, 154.9ms\n",
      "Speed: 0.0ms preprocess, 154.9ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Results saved to \u001b[1mruns\\detect\\predict113\u001b[0m\n",
      "\n",
      "0: 416x160 1 License_Plate, 668.6ms\n",
      "Speed: 9.9ms preprocess, 668.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Results saved to \u001b[1mruns\\detect\\predict114\u001b[0m\n",
      "License_Plate\n",
      "Number Plate Text: TN 78 R 6160\n",
      "\n",
      "0: 416x192 1 person_bike, 757.5ms\n",
      "Speed: 0.0ms preprocess, 757.5ms inference, 8.2ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Results saved to \u001b[1mruns\\detect\\predict112\u001b[0m\n",
      "person_bike True\n",
      "\n",
      "0: 416x160 1 Without Helmet, 137.0ms\n",
      "Speed: 8.4ms preprocess, 137.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Results saved to \u001b[1mruns\\detect\\predict113\u001b[0m\n",
      "\n",
      "0: 416x160 1 License_Plate, 701.2ms\n",
      "Speed: 8.0ms preprocess, 701.2ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 160)\n",
      "Results saved to \u001b[1mruns\\detect\\predict114\u001b[0m\n",
      "License_Plate\n",
      "Number Plate Text: KASZE IND T65z4\n",
      "\n",
      "0: 320x416 2 person_bikes, 1370.5ms\n",
      "Speed: 0.0ms preprocess, 1370.5ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Results saved to \u001b[1mruns\\detect\\predict112\u001b[0m\n",
      "person_bike True\n",
      "\n",
      "0: 416x224 2 Without Helmets, 159.0ms\n",
      "Speed: 4.4ms preprocess, 159.0ms inference, 8.9ms postprocess per image at shape (1, 3, 416, 224)\n",
      "Results saved to \u001b[1mruns\\detect\\predict113\u001b[0m\n",
      "\n",
      "0: 416x224 (no detections), 1108.5ms\n",
      "Speed: 8.0ms preprocess, 1108.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 224)\n",
      "Results saved to \u001b[1mruns\\detect\\predict114\u001b[0m\n",
      "\n",
      "0: 416x224 (no detections), 1296.4ms\n",
      "Speed: 0.0ms preprocess, 1296.4ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 224)\n",
      "Results saved to \u001b[1mruns\\detect\\predict114\u001b[0m\n",
      "person_bike True\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 33\u001b[0m\n\u001b[0;32m     30\u001b[0m person_bike_image \u001b[38;5;241m=\u001b[39m img[\u001b[38;5;28mint\u001b[39m(y1):\u001b[38;5;28mint\u001b[39m(y2), \u001b[38;5;28mint\u001b[39m(x1):\u001b[38;5;28mint\u001b[39m(x2)]\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Detect helmet on the person\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m helmet_results \u001b[38;5;241m=\u001b[39m \u001b[43mhelmet_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mperson_bike_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Process each helmet detection result\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hr \u001b[38;5;129;01min\u001b[39;00m helmet_results:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\engine\\model.py:558\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[0;32m    556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_prompts\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[0;32m    557\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mset_prompts(prompts)\n\u001b[1;32m--> 558\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mpredict_cli(source\u001b[38;5;241m=\u001b[39msource) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\engine\\predictor.py:173\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[1;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 173\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\_contextlib.py:36\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m---> 36\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     40\u001b[0m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\engine\\predictor.py:259\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[1;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m--> 259\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39membed:\n\u001b[0;32m    261\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m [preds] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(preds, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m preds  \u001b[38;5;66;03m# yield embedding tensors\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\engine\\predictor.py:143\u001b[0m, in \u001b[0;36mBasePredictor.inference\u001b[1;34m(self, im, *args, **kwargs)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Runs inference on a given image using the specified model and arguments.\"\"\"\u001b[39;00m\n\u001b[0;32m    138\u001b[0m visualize \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    139\u001b[0m     increment_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_dir \u001b[38;5;241m/\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mstem, mkdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mvisualize \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_type\u001b[38;5;241m.\u001b[39mtensor)\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    142\u001b[0m )\n\u001b[1;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\nn\\autobackend.py:527\u001b[0m, in \u001b[0;36mAutoBackend.forward\u001b[1;34m(self, im, augment, visualize, embed)\u001b[0m\n\u001b[0;32m    525\u001b[0m \u001b[38;5;66;03m# PyTorch\u001b[39;00m\n\u001b[0;32m    526\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpt \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_module:\n\u001b[1;32m--> 527\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    529\u001b[0m \u001b[38;5;66;03m# TorchScript\u001b[39;00m\n\u001b[0;32m    530\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjit:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\nn\\tasks.py:112\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[1;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\nn\\tasks.py:130\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[1;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_augment(x)\n\u001b[1;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\nn\\tasks.py:151\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[1;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[1;32m--> 151\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[0;32m    152\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(x \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\nn\\modules\\block.py:237\u001b[0m, in \u001b[0;36mC2f.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m    236\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass through C2f layer.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 237\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    238\u001b[0m     y\u001b[38;5;241m.\u001b[39mextend(m(y[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm)\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(torch\u001b[38;5;241m.\u001b[39mcat(y, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\nn\\modules\\conv.py:54\u001b[0m, in \u001b[0;36mConv.forward_fuse\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_fuse\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     53\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Apply convolution and activation without batch normalization.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[0;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[0;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[0;32m    548\u001b[0m     )\n\u001b[1;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[0;32m    551\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "# Path to the folder containing images\n",
    "input_folder = r\"C:\\Users\\User\\OneDrive\\Desktop\\Final project\\otest\\otest\\otest\"\n",
    "\n",
    "\n",
    "# Get a list of all image files in the input folder\n",
    "image_files = [os.path.join(input_folder, file) for file in os.listdir(input_folder) if file.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "# Process each image in the folder\n",
    "for image_file in image_files:\n",
    "    # Load the image\n",
    "    img = cv2.imread(image_file)\n",
    "\n",
    "    # Process frame\n",
    "    #img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    # Detect person on a bike\n",
    "    person_bike_results = person_bike_model.predict(img, show=True, save=True)\n",
    "    \n",
    "    # Process each detection result\n",
    "    for r in person_bike_results:\n",
    "        boxes = r.boxes\n",
    "        # Filter detections for person on a bike\n",
    "        for box in boxes:\n",
    "            cls = box.cls\n",
    "            print(person_bike_model.names[int(cls)], person_bike_model.names[int(cls)] == \"person_bike\")\n",
    "            if person_bike_model.names[int(cls)] == \"person_bike\":\n",
    "                # Crop person on a bike image\n",
    "                x1, y1, x2, y2 = box.xyxy[0]\n",
    "                person_bike_image = img[int(y1):int(y2), int(x1):int(x2)]\n",
    "\n",
    "                # Detect helmet on the person\n",
    "                helmet_results = helmet_model.predict(person_bike_image, show=True, save=True)\n",
    "\n",
    "                # Process each helmet detection result\n",
    "                for hr in helmet_results:\n",
    "                    h_boxes = hr.boxes\n",
    "                    # Filter detections for no helmet\n",
    "                    for h_bo in h_boxes:\n",
    "                        h_cls = h_bo.cls\n",
    "                        if not helmet_model.names[int(h_cls)] == \"With Helmet\" :\n",
    "                            # Extract number plate from the person bike image\n",
    "                            number_plate_results = number_plate_model.predict(person_bike_image, show=True, save=True)\n",
    "\n",
    "                            # Process each number plate detection result\n",
    "                            for npr in number_plate_results:\n",
    "                                np_boxes = npr.boxes\n",
    "                                # Filter detections for number plate\n",
    "                                for np_box in np_boxes:\n",
    "                                    np_cls = np_box.cls\n",
    "                                    print(number_plate_model.names[int(np_cls)])\n",
    "                                    if number_plate_model.names[int(np_cls)] == \"License_Plate\":\n",
    "                                        # Crop number plate image\n",
    "                                        np_x1, np_y1, np_x2, np_y2 = np_box.xyxy[0]\n",
    "                                        number_plate_image = person_bike_image[int(np_y1):int(np_y2),\n",
    "                                                             int(np_x1):int(np_x2)]\n",
    "                                        # Save the cropped images of persons on bikes with violations\n",
    "                                        output_file = f\"person_bike_violation_{os.path.basename(image_file)}\"\n",
    "                                        output_path = os.path.join(output_dir, output_file)\n",
    "                                        cv2.imwrite(output_path, person_bike_image)\n",
    "\n",
    "                                        # Save the cropped number plate image\n",
    "                                        output_file_number_plate = f\"number_plate_violation_{os.path.basename(image_file)}\"\n",
    "                                        output_path_number_plate = os.path.join(output_dir, output_file_number_plate)\n",
    "                                        cv2.imwrite(output_path_number_plate, number_plate_image)\n",
    "                                        results=reader.readtext(number_plate_image)\n",
    "                                        text=\" \".join([res[1] for res in results]) if results else \"....\" \n",
    "                                        #gray = cv2.cvtColor(number_plate_image, cv2.COLOR_BGR2GRAY)\n",
    "                                        #text = EasyOCR.image_to_string(gray)\n",
    "                                        # Example usage\n",
    "                                        # Create the \"vehicles\" table if it doesn't exist\n",
    "                                        create_table()\n",
    "                                        # Insert two records into the \"vehicles\" table\n",
    "                                        insert_record(text, output_path)\n",
    "                                        # Print the extracted text\n",
    "                                        print(\"Number Plate Text:\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee4b615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 416x256 1 person_bike, 2092.5ms\n",
      "Speed: 9.1ms preprocess, 2092.5ms inference, 2.6ms postprocess per image at shape (1, 3, 416, 256)\n",
      "person_bike True\n",
      "\n",
      "0: 416x192 1 Without Helmet, 175.1ms\n",
      "Speed: 3.0ms preprocess, 175.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "\n",
      "0: 416x192 (no detections), 1037.7ms\n",
      "Speed: 2.0ms preprocess, 1037.7ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "\n",
      "0: 416x256 1 person_bike, 1055.3ms\n",
      "Speed: 3.0ms preprocess, 1055.3ms inference, 2.0ms postprocess per image at shape (1, 3, 416, 256)\n",
      "person_bike True\n",
      "\n",
      "0: 416x192 1 Without Helmet, 161.7ms\n",
      "Speed: 3.0ms preprocess, 161.7ms inference, 2.9ms postprocess per image at shape (1, 3, 416, 192)\n",
      "\n",
      "0: 416x192 (no detections), 815.9ms\n",
      "Speed: 3.0ms preprocess, 815.9ms inference, 0.9ms postprocess per image at shape (1, 3, 416, 192)\n",
      "\n",
      "0: 416x256 1 person_bike, 1118.9ms\n",
      "Speed: 3.0ms preprocess, 1118.9ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 256)\n",
      "person_bike True\n",
      "\n",
      "0: 416x192 1 Without Helmet, 162.2ms\n",
      "Speed: 8.1ms preprocess, 162.2ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "\n",
      "0: 416x192 (no detections), 1125.3ms\n",
      "Speed: 2.0ms preprocess, 1125.3ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 192)\n",
      "\n",
      "0: 416x256 1 person_bike, 1107.1ms\n",
      "Speed: 3.3ms preprocess, 1107.1ms inference, 11.9ms postprocess per image at shape (1, 3, 416, 256)\n",
      "person_bike True\n",
      "\n",
      "0: 416x192 1 Without Helmet, 158.3ms\n",
      "Speed: 9.1ms preprocess, 158.3ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "\n",
      "0: 416x192 (no detections), 815.1ms\n",
      "Speed: 2.0ms preprocess, 815.1ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "\n",
      "0: 416x256 1 person_bike, 1059.6ms\n",
      "Speed: 2.1ms preprocess, 1059.6ms inference, 2.0ms postprocess per image at shape (1, 3, 416, 256)\n",
      "person_bike True\n",
      "\n",
      "0: 416x192 1 Without Helmet, 170.9ms\n",
      "Speed: 7.1ms preprocess, 170.9ms inference, 3.6ms postprocess per image at shape (1, 3, 416, 192)\n",
      "\n",
      "0: 416x192 (no detections), 970.5ms\n",
      "Speed: 3.0ms preprocess, 970.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "\n",
      "0: 416x256 1 person_bike, 1263.3ms\n",
      "Speed: 3.3ms preprocess, 1263.3ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 256)\n",
      "person_bike True\n",
      "\n",
      "0: 416x192 1 Without Helmet, 213.2ms\n",
      "Speed: 7.4ms preprocess, 213.2ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "\n",
      "0: 416x192 (no detections), 1012.5ms\n",
      "Speed: 4.0ms preprocess, 1012.5ms inference, 2.2ms postprocess per image at shape (1, 3, 416, 192)\n",
      "\n",
      "0: 416x256 1 person_bike, 1202.4ms\n",
      "Speed: 3.0ms preprocess, 1202.4ms inference, 3.3ms postprocess per image at shape (1, 3, 416, 256)\n",
      "person_bike True\n",
      "\n",
      "0: 416x192 1 Without Helmet, 178.7ms\n",
      "Speed: 8.5ms preprocess, 178.7ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "\n",
      "0: 416x192 (no detections), 982.4ms\n",
      "Speed: 3.0ms preprocess, 982.4ms inference, 0.8ms postprocess per image at shape (1, 3, 416, 192)\n",
      "\n",
      "0: 416x256 1 person_bike, 1193.4ms\n",
      "Speed: 3.2ms preprocess, 1193.4ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 256)\n",
      "person_bike True\n",
      "\n",
      "0: 416x192 1 Without Helmet, 166.3ms\n",
      "Speed: 4.5ms preprocess, 166.3ms inference, 2.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "\n",
      "0: 416x192 (no detections), 841.9ms\n",
      "Speed: 3.0ms preprocess, 841.9ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "\n",
      "0: 416x256 1 person_bike, 1225.3ms\n",
      "Speed: 2.0ms preprocess, 1225.3ms inference, 2.0ms postprocess per image at shape (1, 3, 416, 256)\n",
      "person_bike True\n",
      "\n",
      "0: 416x192 1 Without Helmet, 159.0ms\n",
      "Speed: 9.6ms preprocess, 159.0ms inference, 3.5ms postprocess per image at shape (1, 3, 416, 192)\n",
      "\n",
      "0: 416x192 (no detections), 812.6ms\n",
      "Speed: 1.8ms preprocess, 812.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "\n",
      "0: 416x256 1 person_bike, 1072.9ms\n",
      "Speed: 3.0ms preprocess, 1072.9ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 256)\n",
      "person_bike True\n",
      "\n",
      "0: 416x192 1 Without Helmet, 171.4ms\n",
      "Speed: 3.0ms preprocess, 171.4ms inference, 2.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "\n",
      "0: 416x192 (no detections), 819.5ms\n",
      "Speed: 3.0ms preprocess, 819.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "\n",
      "0: 416x256 1 person_bike, 1078.7ms\n",
      "Speed: 3.0ms preprocess, 1078.7ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 256)\n",
      "person_bike True\n",
      "\n",
      "0: 416x192 1 Without Helmet, 180.9ms\n",
      "Speed: 17.5ms preprocess, 180.9ms inference, 2.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "\n",
      "0: 416x192 (no detections), 820.7ms\n",
      "Speed: 3.0ms preprocess, 820.7ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "\n",
      "0: 416x256 1 person_bike, 1065.1ms\n",
      "Speed: 4.0ms preprocess, 1065.1ms inference, 3.0ms postprocess per image at shape (1, 3, 416, 256)\n",
      "person_bike True\n",
      "\n",
      "0: 416x192 1 Without Helmet, 195.6ms\n",
      "Speed: 3.0ms preprocess, 195.6ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "\n",
      "0: 416x192 (no detections), 1024.7ms\n",
      "Speed: 3.3ms preprocess, 1024.7ms inference, 2.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "\n",
      "0: 416x256 1 person_bike, 1584.4ms\n",
      "Speed: 5.0ms preprocess, 1584.4ms inference, 2.0ms postprocess per image at shape (1, 3, 416, 256)\n",
      "person_bike True\n",
      "\n",
      "0: 416x192 1 Without Helmet, 169.0ms\n",
      "Speed: 6.0ms preprocess, 169.0ms inference, 2.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "\n",
      "0: 416x192 (no detections), 789.3ms\n",
      "Speed: 2.0ms preprocess, 789.3ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "\n",
      "0: 416x256 1 person_bike, 953.1ms\n",
      "Speed: 0.0ms preprocess, 953.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 256)\n",
      "person_bike True\n",
      "\n",
      "0: 416x192 1 Without Helmet, 187.5ms\n",
      "Speed: 0.0ms preprocess, 187.5ms inference, 15.6ms postprocess per image at shape (1, 3, 416, 192)\n",
      "\n",
      "0: 416x192 1 License_Plate, 749.9ms\n",
      "Speed: 0.0ms preprocess, 749.9ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "License_Plate\n",
      "Number Plate Text: N/A\n",
      "WARNING  'source' is missing. Using 'source=C:\\Users\\User\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\assets'.\n",
      "\n",
      "image 1/2 C:\\Users\\User\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\assets\\bus.jpg: 416x320 1 person_bike, 2406.4ms\n",
      "image 2/2 C:\\Users\\User\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\assets\\zidane.jpg: 256x416 2 person_bikes, 2031.4ms\n",
      "Speed: 7.8ms preprocess, 2218.9ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "person_bike True\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m person_bike_model\u001b[38;5;241m.\u001b[39mnames[\u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mcls\u001b[39m)] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mperson_bike\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;66;03m# Crop person on a bike image\u001b[39;00m\n\u001b[0;32m     21\u001b[0m     x1, y1, x2, y2 \u001b[38;5;241m=\u001b[39m box\u001b[38;5;241m.\u001b[39mxyxy[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 22\u001b[0m     person_bike_image \u001b[38;5;241m=\u001b[39m \u001b[43mframe\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;66;03m# Detect helmet on the person\u001b[39;00m\n\u001b[0;32m     25\u001b[0m     helmet_results \u001b[38;5;241m=\u001b[39m helmet_model\u001b[38;5;241m.\u001b[39mpredict(person_bike_image)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77f172b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 416x256 1 person_bike, 1545.0ms\n",
      "Speed: 0.0ms preprocess, 1545.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 256)\n",
      "\n",
      "0: 416x192 1 Without Helmet, 216.7ms\n",
      "Speed: 8.6ms preprocess, 216.7ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "\n",
      "0: 416x192 (no detections), 828.5ms\n",
      "Speed: 0.0ms preprocess, 828.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "\n",
      "0: 416x256 1 person_bike, 1122.1ms\n",
      "Speed: 0.0ms preprocess, 1122.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 256)\n",
      "\n",
      "0: 416x192 1 Without Helmet, 178.5ms\n",
      "Speed: 8.1ms preprocess, 178.5ms inference, 8.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "\n",
      "0: 416x192 (no detections), 787.7ms\n",
      "Speed: 5.9ms preprocess, 787.7ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "\n",
      "0: 416x256 1 person_bike, 1024.1ms\n",
      "Speed: 0.0ms preprocess, 1024.1ms inference, 8.0ms postprocess per image at shape (1, 3, 416, 256)\n",
      "\n",
      "0: 416x192 1 Without Helmet, 142.4ms\n",
      "Speed: 8.3ms preprocess, 142.4ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "\n",
      "0: 416x192 (no detections), 812.1ms\n",
      "Speed: 0.0ms preprocess, 812.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "\n",
      "0: 416x256 1 person_bike, 1143.6ms\n",
      "Speed: 0.0ms preprocess, 1143.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 256)\n",
      "\n",
      "0: 416x192 1 Without Helmet, 173.6ms\n",
      "Speed: 10.5ms preprocess, 173.6ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 192)\n",
      "\n",
      "0: 416x192 (no detections), 805.5ms\n",
      "Speed: 0.0ms preprocess, 805.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "\n",
      "0: 416x256 1 person_bike, 993.4ms\n",
      "Speed: 0.0ms preprocess, 993.4ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 256)\n",
      "\n",
      "0: 416x192 1 Without Helmet, 159.6ms\n",
      "Speed: 0.0ms preprocess, 159.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "\n",
      "0: 416x192 (no detections), 783.3ms\n",
      "Speed: 0.0ms preprocess, 783.3ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "\n",
      "0: 416x256 1 person_bike, 1023.6ms\n",
      "Speed: 9.3ms preprocess, 1023.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 256)\n",
      "\n",
      "0: 416x192 1 Without Helmet, 141.4ms\n",
      "Speed: 35.6ms preprocess, 141.4ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "\n",
      "0: 416x192 (no detections), 778.1ms\n",
      "Speed: 5.9ms preprocess, 778.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "\n",
      "0: 416x256 1 person_bike, 986.5ms\n",
      "Speed: 8.0ms preprocess, 986.5ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 256)\n",
      "\n",
      "0: 416x192 1 Without Helmet, 215.4ms\n",
      "Speed: 0.0ms preprocess, 215.4ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "\n",
      "0: 416x192 (no detections), 776.6ms\n",
      "Speed: 0.0ms preprocess, 776.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "\n",
      "0: 416x256 1 person_bike, 988.0ms\n",
      "Speed: 0.0ms preprocess, 988.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 256)\n",
      "\n",
      "0: 416x192 1 Without Helmet, 160.3ms\n",
      "Speed: 11.9ms preprocess, 160.3ms inference, 14.5ms postprocess per image at shape (1, 3, 416, 192)\n",
      "\n",
      "0: 416x192 (no detections), 761.7ms\n",
      "Speed: 0.0ms preprocess, 761.7ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "\n",
      "0: 416x256 1 person_bike, 998.0ms\n",
      "Speed: 13.8ms preprocess, 998.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 256)\n",
      "\n",
      "0: 416x192 1 Without Helmet, 167.6ms\n",
      "Speed: 8.2ms preprocess, 167.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "\n",
      "0: 416x192 (no detections), 759.7ms\n",
      "Speed: 8.0ms preprocess, 759.7ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "\n",
      "0: 416x256 1 person_bike, 1009.7ms\n",
      "Speed: 0.0ms preprocess, 1009.7ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 256)\n",
      "\n",
      "0: 416x192 1 Without Helmet, 164.3ms\n",
      "Speed: 5.4ms preprocess, 164.3ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "\n",
      "0: 416x192 (no detections), 739.6ms\n",
      "Speed: 8.0ms preprocess, 739.6ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "\n",
      "0: 416x256 1 person_bike, 1093.9ms\n",
      "Speed: 8.0ms preprocess, 1093.9ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 256)\n",
      "\n",
      "0: 416x192 1 Without Helmet, 175.1ms\n",
      "Speed: 0.0ms preprocess, 175.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "\n",
      "0: 416x192 (no detections), 764.7ms\n",
      "Speed: 4.1ms preprocess, 764.7ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "\n",
      "0: 416x256 1 person_bike, 983.0ms\n",
      "Speed: 8.0ms preprocess, 983.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 256)\n",
      "\n",
      "0: 416x192 1 Without Helmet, 142.7ms\n",
      "Speed: 10.2ms preprocess, 142.7ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "\n",
      "0: 416x192 (no detections), 758.2ms\n",
      "Speed: 0.0ms preprocess, 758.2ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "\n",
      "0: 416x256 1 person_bike, 1031.4ms\n",
      "Speed: 0.0ms preprocess, 1031.4ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 256)\n",
      "\n",
      "0: 416x192 1 Without Helmet, 164.2ms\n",
      "Speed: 0.0ms preprocess, 164.2ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "\n",
      "0: 416x192 (no detections), 763.2ms\n",
      "Speed: 7.9ms preprocess, 763.2ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "\n",
      "0: 416x256 1 person_bike, 1002.9ms\n",
      "Speed: 10.3ms preprocess, 1002.9ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 256)\n",
      "\n",
      "0: 416x192 1 Without Helmet, 182.1ms\n",
      "Speed: 0.0ms preprocess, 182.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "\n",
      "0: 416x192 1 License_Plate, 913.9ms\n",
      "Speed: 0.0ms preprocess, 913.9ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Number Plate Text: N/A\n",
      "\n",
      "0: 416x256 1 person_bike, 995.5ms\n",
      "Speed: 8.0ms preprocess, 995.5ms inference, 8.0ms postprocess per image at shape (1, 3, 416, 256)\n",
      "\n",
      "0: 416x192 1 Without Helmet, 297.7ms\n",
      "Speed: 0.0ms preprocess, 297.7ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "\n",
      "0: 416x192 1 License_Plate, 942.0ms\n",
      "Speed: 0.0ms preprocess, 942.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Number Plate Text: N/A\n",
      "\n",
      "0: 416x256 1 person_bike, 1803.1ms\n",
      "Speed: 0.0ms preprocess, 1803.1ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 256)\n",
      "\n",
      "0: 416x192 1 Without Helmet, 171.9ms\n",
      "Speed: 16.2ms preprocess, 171.9ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 192)\n",
      "\n",
      "0: 416x192 1 License_Plate, 772.5ms\n",
      "Speed: 8.0ms preprocess, 772.5ms inference, 0.9ms postprocess per image at shape (1, 3, 416, 192)\n",
      "Number Plate Text: TOTre\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Detect person on a bike\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m person_bike_results \u001b[38;5;241m=\u001b[39m \u001b[43mperson_bike_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m person_bike_results:\n\u001b[0;32m     18\u001b[0m     boxes \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mboxes\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\engine\\model.py:558\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[0;32m    556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_prompts\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[0;32m    557\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mset_prompts(prompts)\n\u001b[1;32m--> 558\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mpredict_cli(source\u001b[38;5;241m=\u001b[39msource) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\engine\\predictor.py:173\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[1;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 173\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\_contextlib.py:36\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m---> 36\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     40\u001b[0m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\engine\\predictor.py:259\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[1;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m--> 259\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39membed:\n\u001b[0;32m    261\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m [preds] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(preds, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m preds  \u001b[38;5;66;03m# yield embedding tensors\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\engine\\predictor.py:143\u001b[0m, in \u001b[0;36mBasePredictor.inference\u001b[1;34m(self, im, *args, **kwargs)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Runs inference on a given image using the specified model and arguments.\"\"\"\u001b[39;00m\n\u001b[0;32m    138\u001b[0m visualize \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    139\u001b[0m     increment_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_dir \u001b[38;5;241m/\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mstem, mkdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mvisualize \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_type\u001b[38;5;241m.\u001b[39mtensor)\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    142\u001b[0m )\n\u001b[1;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\nn\\autobackend.py:527\u001b[0m, in \u001b[0;36mAutoBackend.forward\u001b[1;34m(self, im, augment, visualize, embed)\u001b[0m\n\u001b[0;32m    525\u001b[0m \u001b[38;5;66;03m# PyTorch\u001b[39;00m\n\u001b[0;32m    526\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpt \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_module:\n\u001b[1;32m--> 527\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    529\u001b[0m \u001b[38;5;66;03m# TorchScript\u001b[39;00m\n\u001b[0;32m    530\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjit:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\nn\\tasks.py:112\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[1;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\nn\\tasks.py:130\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[1;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_augment(x)\n\u001b[1;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\nn\\tasks.py:151\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[1;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[1;32m--> 151\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[0;32m    152\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(x \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\nn\\modules\\block.py:238\u001b[0m, in \u001b[0;36mC2f.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass through C2f layer.\"\"\"\u001b[39;00m\n\u001b[0;32m    237\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x)\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m--> 238\u001b[0m \u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(torch\u001b[38;5;241m.\u001b[39mcat(y, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\nn\\modules\\block.py:238\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass through C2f layer.\"\"\"\u001b[39;00m\n\u001b[0;32m    237\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x)\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m--> 238\u001b[0m y\u001b[38;5;241m.\u001b[39mextend(\u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm)\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(torch\u001b[38;5;241m.\u001b[39mcat(y, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\nn\\modules\\block.py:347\u001b[0m, in \u001b[0;36mBottleneck.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m    346\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Applies the YOLO FPN to input data.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x)) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\nn\\modules\\conv.py:54\u001b[0m, in \u001b[0;36mConv.forward_fuse\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_fuse\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     53\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Apply convolution and activation without batch normalization.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[0;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[0;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[0;32m    548\u001b[0m     )\n\u001b[1;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[0;32m    551\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Output directory\n",
    "output_dir1 = r\"C:\\Users\\User\\OneDrive\\Desktop\\Final project\\output_dir1\"\n",
    "os.makedirs(output_dir1, exist_ok=True)\n",
    "\n",
    "# Open video\n",
    "video_capture = cv2.VideoCapture(r'C:\\Users\\User\\OneDrive\\Desktop\\Final project\\project video.mp4')\n",
    "\n",
    "while True:\n",
    "    ret, frame = video_capture.read()\n",
    "    if not ret or frame is None:\n",
    "        print(\"End of video or can't read frame. Exiting...\")\n",
    "        break\n",
    "\n",
    "    # Detect person on a bike\n",
    "    person_bike_results = person_bike_model.predict(frame)\n",
    "\n",
    "    for r in person_bike_results:\n",
    "        boxes = r.boxes\n",
    "        for box in boxes:\n",
    "            cls = box.cls\n",
    "            if person_bike_model.names[int(cls)] == \"person_bike\":\n",
    "                x1, y1, x2, y2 = box.xyxy[0]\n",
    "                h, w = frame.shape[:2]\n",
    "                x1 = max(0, int(x1))\n",
    "                y1 = max(0, int(y1))\n",
    "                x2 = min(w, int(x2))\n",
    "                y2 = min(h, int(y2))\n",
    "                person_bike_image = frame[y1:y2, x1:x2]\n",
    "\n",
    "                if person_bike_image is None or person_bike_image.size == 0:\n",
    "                    print(\"Invalid person-bike crop. Skipping...\")\n",
    "                    continue\n",
    "\n",
    "                # Detect helmet\n",
    "                helmet_results = helmet_model.predict(person_bike_image)\n",
    "\n",
    "                for hr in helmet_results:\n",
    "                    h_boxes = hr.boxes\n",
    "                    for h_bo in h_boxes:\n",
    "                        h_cls = h_bo.cls\n",
    "                        if helmet_model.names[int(h_cls)] != \"With Helmet\":\n",
    "                            # Detect number plate\n",
    "                            number_plate_results = number_plate_model.predict(person_bike_image)\n",
    "\n",
    "                            for npr in number_plate_results:\n",
    "                                np_boxes = npr.boxes\n",
    "                                for np_box in np_boxes:\n",
    "                                    np_cls = np_box.cls\n",
    "                                    if number_plate_model.names[int(np_cls)] == \"License_Plate\":\n",
    "                                        np_x1, np_y1, np_x2, np_y2 = np_box.xyxy[0]\n",
    "                                        h2, w2 = person_bike_image.shape[:2]\n",
    "                                        np_x1 = max(0, int(np_x1))\n",
    "                                        np_y1 = max(0, int(np_y1))\n",
    "                                        np_x2 = min(w2, int(np_x2))\n",
    "                                        np_y2 = min(h2, int(np_y2))\n",
    "                                        number_plate_image = person_bike_image[np_y1:np_y2, np_x1:np_x2]\n",
    "\n",
    "                                        if number_plate_image is None or number_plate_image.size == 0:\n",
    "                                            print(\"Invalid number plate crop. Skipping...\")\n",
    "                                            continue\n",
    "\n",
    "                                        # Save cropped image\n",
    "                                        output_file = f\"violation_{len(os.listdir(output_dir1)) + 1}.jpg\"\n",
    "                                        output_path = os.path.join(output_dir1, output_file)\n",
    "                                        cv2.imwrite(output_path, person_bike_image)\n",
    "\n",
    "                                        # OCR\n",
    "                                        results = reader.readtext(number_plate_image)\n",
    "                                        text = \" \".join([res[1] for res in results]) if results else \"N/A\"\n",
    "                                        print(\"Number Plate Text:\", text)\n",
    "\n",
    "                                        # DB functions (make sure you define these elsewhere)\n",
    "                                        create_table()\n",
    "                                        insert_record(text, output_path)\n",
    "\n",
    "# Cleanup\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb7b32c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
